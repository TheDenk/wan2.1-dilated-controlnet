{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aafe5a-4236-42b0-aa0c-4cec794408d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For visualisation\n",
    "!pip install denku==0.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4f577-c41e-427b-aa68-1d5e87d95ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from denku import show_images\n",
    "from diffusers import (\n",
    "    AutoencoderKLWan,\n",
    "    FlowMatchEulerDiscreteScheduler,\n",
    "    UniPCMultistepScheduler\n",
    ")\n",
    "from diffusers.utils import export_to_video, load_video\n",
    "from controlnet_aux import HEDdetector, CannyDetector\n",
    "from transformers import UMT5EncoderModel, T5TokenizerFast\n",
    "\n",
    "\n",
    "from wan_controlnet import WanControlnet\n",
    "from wan_transformer import CustomWanTransformer3DModel\n",
    "from wan_controlnet_pipeline import WanControlnetPipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20edac-0243-4a28-9a0e-1acccc562e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\"\n",
    "controlnet_model_path = \"TheDenk/wan2.1-t2v-1.3b-controlnet-hed-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b5583-1335-436c-9b81-3028e1beb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(base_model_path, subfolder=\"tokenizer\")\n",
    "text_encoder = UMT5EncoderModel.from_pretrained(base_model_path, subfolder=\"text_encoder\", torch_dtype=torch.bfloat16)\n",
    "vae = AutoencoderKLWan.from_pretrained(base_model_path, subfolder=\"vae\", torch_dtype=torch.float32)\n",
    "transformer = CustomWanTransformer3DModel.from_pretrained(base_model_path, subfolder=\"transformer\", torch_dtype=torch.bfloat16)\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(base_model_path, subfolder=\"scheduler\")\n",
    "# flow_shift = 3.0 # 5.0 for 720P, 3.0 for 480P\n",
    "# scheduler = UniPCMultistepScheduler(prediction_type='flow_prediction', use_flow_sigmas=True, num_train_timesteps=1000, flow_shift=flow_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7b420-34c5-4bb9-a0b0-d64b0f082ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = WanControlnet.from_pretrained(controlnet_model_path, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a8fa0-85ed-492b-a1eb-27ca2551d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = WanControlnetPipeline(\n",
    "    tokenizer=tokenizer, \n",
    "    text_encoder=text_encoder,\n",
    "    transformer=transformer,\n",
    "    vae=vae, \n",
    "    controlnet=controlnet,\n",
    "    scheduler=scheduler,\n",
    ")\n",
    "pipe = pipe.to(device=\"cuda\")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f73d86-b0e9-4407-b7e0-6c23c56e8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_controlnet_processor(controlnet_type):\n",
    "    if controlnet_type in ['canny']:\n",
    "        return controlnet_mapping[controlnet_type]()\n",
    "    return controlnet_mapping[controlnet_type].from_pretrained('lllyasviel/Annotators').to(device='cuda')\n",
    "\n",
    "controlnet_mapping = {\n",
    "    'hed': HEDdetector,\n",
    "    'canny': CannyDetector,\n",
    "}\n",
    "\n",
    "controlnet_processor = init_controlnet_processor(\"hed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3eae1-1a94-40db-a4fc-608ea1f7fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../resources/physical-1.mp4\"\n",
    "num_frames = 81\n",
    "\n",
    "video_frames = load_video(video_path)[:num_frames]\n",
    "controlnet_frames = [controlnet_processor(x) for x in video_frames]\n",
    "\n",
    "show_images(video_frames[::20], figsize=(16, 8))\n",
    "show_images(controlnet_frames[::20], figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d2dd5-a2fe-421c-b668-0123ef8936e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In a cozy kitchen, a golden retriever wearing a white chef's hat and a blue apron stands at the table, holding a sharp kitchen knife and skillfully slicing fresh tomatoes. Its tail sways gently, and its gaze is focused and gentle. There are already several neatly arranged tomatoes on the wooden chopping board in front of me. The kitchen has soft lighting, with various kitchen utensils hanging on the walls and several pots of green plants placed on the windowsill.\"\n",
    "negative_prompt = \"Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    height=480,\n",
    "    width=832,\n",
    "    num_frames=num_frames,\n",
    "    guidance_scale=5.0,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    "    output_type=\"pil\",\n",
    "\n",
    "    controlnet_frames=controlnet_frames,\n",
    "    controlnet_guidance_start=0.0,\n",
    "    controlnet_guidance_end=0.8,\n",
    "    controlnet_weight=0.8,\n",
    "    controlnet_stride=3,\n",
    ").frames[0]\n",
    "\n",
    "show_images(output[::20], figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d54b7-dab6-4a7e-8db1-8404600505b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output.mp4\"\n",
    "export_to_video(output, output_path, fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295d8c0-82f9-42b2-9c95-3a95c1ba0983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2319560-a345-454f-8cfe-21ff932f4015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ebddc-fb5f-474e-9791-5fac84301a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
